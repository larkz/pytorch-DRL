{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "GeForce RTX 3080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow_gpu-2.7.0-cp38-cp38-manylinux2010_x86_64.whl (489.6 MB)\n",
      "\u001b[K     |███████████████████▌            | 299.1 MB 104.3 MB/s eta 0:00:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 489.6 MB 106.4 MB/s \n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 82.3 MB/s \n",
      "\u001b[?25hCollecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "\u001b[K     |████████████████████████████████| 463 kB 164.6 MB/s \n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.22.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 139.1 MB/s \n",
      "\u001b[?25hCollecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 127.8 MB/s \n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 128.9 MB/s \n",
      "\u001b[?25hCollecting six>=1.12.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 97.3 MB/s \n",
      "\u001b[?25hCollecting libclang>=9.0.1\n",
      "  Downloading libclang-12.0.0-py2.py3-none-manylinux1_x86_64.whl (13.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.4 MB 70.8 MB/s \n",
      "\u001b[?25hCollecting wheel<1.0,>=0.32.0\n",
      "  Downloading wheel-0.37.0-py2.py3-none-any.whl (35 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.13.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 117.5 MB/s \n",
      "\u001b[?25hCollecting gast<0.5.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting numpy>=1.14.5\n",
      "  Downloading numpy-1.21.4-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.7 MB 128.2 MB/s \n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.42.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 162.6 MB/s \n",
      "\u001b[?25hCollecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 146.6 MB/s \n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 129.7 MB/s \n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.6.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.5 MB 146.2 MB/s \n",
      "\u001b[?25hCollecting keras<2.8,>=2.7.0rc0\n",
      "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 155.8 MB/s \n",
      "\u001b[?25hCollecting flatbuffers<3.0,>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.0.1-py3-none-any.whl (22 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting setuptools>=41.0.0\n",
      "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
      "\u001b[K     |████████████████████████████████| 952 kB 154.0 MB/s \n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 138.2 MB/s \n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 63.7 MB/s \n",
      "\u001b[?25hCollecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 68.1 MB/s \n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 122.4 MB/s \n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 127.4 MB/s \n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
      "\u001b[K     |████████████████████████████████| 288 kB 125.8 MB/s \n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 138.2 MB/s \n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.8.2-py3-none-any.whl (17 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 125.9 MB/s \n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "\u001b[K     |████████████████████████████████| 149 kB 128.9 MB/s \n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 125.9 MB/s \n",
      "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.9-py3-none-any.whl (39 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 141.8 MB/s \n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 156.4 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=bb16f2cc74ba51cc0d0b9a8a32f874f69ac925e1a5f89cf2ad83f0d350f9e2c5\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-j6_ffl1z/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, certifi, zipp, six, setuptools, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, wheel, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow-gpu\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorforce 0.6.5 requires h5py~=3.1.0, but you have h5py 3.6.0 which is incompatible.\n",
      "tensorforce 0.6.5 requires numpy==1.19.5, but you have numpy 1.21.4 which is incompatible.\n",
      "tensorflow 2.6.0 requires absl-py~=0.10, but you have absl-py 1.0.0 which is incompatible.\n",
      "tensorflow 2.6.0 requires flatbuffers~=1.12.0, but you have flatbuffers 2.0 which is incompatible.\n",
      "tensorflow 2.6.0 requires h5py~=3.1.0, but you have h5py 3.6.0 which is incompatible.\n",
      "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.4 which is incompatible.\n",
      "tensorflow 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
      "tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.0.1 which is incompatible.\n",
      "tensorflow 2.6.0 requires wrapt~=1.12.1, but you have wrapt 1.13.3 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-4.2.4 certifi-2021.10.8 charset-normalizer-2.0.9 flatbuffers-2.0 gast-0.4.0 google-auth-2.3.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.42.0 h5py-3.6.0 idna-3.3 importlib-metadata-4.8.2 keras-2.7.0 keras-preprocessing-1.1.2 libclang-12.0.0 markdown-3.3.6 numpy-1.21.4 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.19.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.8 setuptools-59.5.0 six-1.16.0 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-estimator-2.7.0 tensorflow-gpu-2.7.0 tensorflow-io-gcs-filesystem-0.22.0 termcolor-1.1.0 typing-extensions-4.0.1 urllib3-1.26.7 werkzeug-2.0.2 wheel-0.37.0 wrapt-1.13.3 zipp-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --ignore-installed --upgrade tensorflow-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/liul-storage/pytorch-DRL/common/Model.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.output_act(self.fc3(out))\n",
      "Episode 100, Average Reward 98.70\n",
      "Episode 200, Average Reward 59.00\n",
      "Episode 300, Average Reward 125.80\n",
      "Episode 400, Average Reward 188.30\n",
      "Episode 500, Average Reward 144.80\n",
      "Episode 600, Average Reward 121.20\n",
      "Episode 700, Average Reward 55.80\n",
      "Episode 800, Average Reward 113.70\n",
      "Episode 900, Average Reward 200.00\n",
      "Episode 1000, Average Reward 200.00\n",
      "Episode 1100, Average Reward 182.60\n",
      "Episode 1200, Average Reward 193.40\n",
      "Episode 1300, Average Reward 192.80\n",
      "Episode 1400, Average Reward 133.90\n",
      "Episode 1500, Average Reward 185.80\n",
      "Episode 1600, Average Reward 198.30\n",
      "Episode 1700, Average Reward 200.00\n",
      "Episode 1800, Average Reward 173.40\n",
      "Episode 1900, Average Reward 200.00\n",
      "Episode 2000, Average Reward 162.30\n",
      "Episode 2100, Average Reward 200.00\n",
      "Episode 2200, Average Reward 200.00\n",
      "Episode 2300, Average Reward 200.00\n",
      "Episode 2400, Average Reward 200.00\n",
      "Episode 2500, Average Reward 200.00\n",
      "Episode 2600, Average Reward 200.00\n",
      "Episode 2700, Average Reward 200.00\n",
      "Episode 2800, Average Reward 200.00\n",
      "Episode 2900, Average Reward 196.00\n",
      "Episode 3000, Average Reward 189.60\n",
      "Episode 3100, Average Reward 200.00\n",
      "Episode 3200, Average Reward 200.00\n",
      "Episode 3300, Average Reward 200.00\n",
      "Episode 3400, Average Reward 200.00\n",
      "Episode 3500, Average Reward 200.00\n",
      "Episode 3600, Average Reward 78.30\n",
      "Episode 3700, Average Reward 200.00\n",
      "Episode 3800, Average Reward 200.00\n",
      "Episode 3900, Average Reward 200.00\n",
      "Episode 4000, Average Reward 200.00\n",
      "Episode 4100, Average Reward 200.00\n",
      "Episode 4200, Average Reward 200.00\n",
      "Episode 4300, Average Reward 200.00\n",
      "Episode 4400, Average Reward 200.00\n",
      "Episode 4500, Average Reward 198.80\n",
      "Episode 4600, Average Reward 200.00\n",
      "Episode 4700, Average Reward 200.00\n",
      "Episode 4800, Average Reward 200.00\n",
      "Episode 4900, Average Reward 200.00\n",
      "Episode 5000, Average Reward 200.00\n"
     ]
    }
   ],
   "source": [
    "# !python run_ppo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/liul-storage/pytorch-DRL/common/Model.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.output_act(self.fc3(out))\n",
      "action 0\n",
      "[1, 1]\n",
      "actions 0\n",
      "[[array([0., 1.]), array([0., 1.])]]\n",
      "actions 1\n",
      "[1, 0]\n",
      "action 0\n",
      "[1, 1]\n",
      "actions 0\n",
      "[[array([0., 1.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])]]\n",
      "actions 1\n",
      "[0, 0]\n",
      "action 0\n",
      "[0, 1]\n",
      "actions 0\n",
      "[[array([0., 1.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([1., 0.])], [array([1., 0.]), array([0., 1.])]]\n",
      "actions 1\n",
      "[1, 0]\n",
      "action 0\n",
      "[1, 1]\n",
      "actions 0\n",
      "[[array([0., 1.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([1., 0.])], [array([1., 0.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])]]\n",
      "actions 1\n",
      "[0, 0]\n",
      "action 0\n",
      "[1, 0]\n",
      "actions 0\n",
      "[[array([0., 1.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([1., 0.])], [array([1., 0.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([1., 0.])], [array([0., 1.]), array([1., 0.])]]\n",
      "actions 1\n",
      "[1, 1]\n",
      "action 0\n",
      "[0, 1]\n",
      "actions 0\n",
      "[[array([0., 1.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([1., 0.])], [array([1., 0.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([1., 0.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([0., 1.])]]\n",
      "actions 1\n",
      "[1, 0]\n",
      "action 0\n",
      "[0, 1]\n",
      "actions 0\n",
      "[[array([0., 1.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([1., 0.])], [array([1., 0.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([1., 0.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([1., 0.]), array([0., 1.])]]\n",
      "actions 1\n",
      "[0, 1]\n",
      "action 0\n",
      "[1, 1]\n",
      "actions 0\n",
      "[[array([0., 1.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([1., 0.])], [array([1., 0.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([1., 0.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([1., 0.]), array([0., 1.])], [array([1., 0.]), array([0., 1.])], [array([0., 1.]), array([0., 1.])]]\n",
      "actions 1\n",
      "[1, 0]\n",
      "action 0\n",
      "[0, 0]\n",
      "actions 0\n",
      "[[array([0., 1.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([1., 0.])], [array([1., 0.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([1., 0.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([1., 0.]), array([0., 1.])], [array([1., 0.]), array([0., 1.])], [array([0., 1.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([1., 0.]), array([1., 0.])]]\n",
      "actions 1\n",
      "[0, 0]\n",
      "action 0\n",
      "[1, 1]\n",
      "actions 0\n",
      "[[array([0., 1.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([1., 0.])], [array([1., 0.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([1., 0.])], [array([0., 1.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])], [array([1., 0.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([1., 0.]), array([0., 1.])], [array([1., 0.]), array([0., 1.])], [array([0., 1.]), array([0., 1.])], [array([0., 1.]), array([1., 0.])], [array([1., 0.]), array([1., 0.])], [array([1., 0.]), array([1., 0.])], [array([0., 1.]), array([0., 1.])]]\n",
      "/opt/conda/lib/python3.8/site-packages/gym/envs/classic_control/cartpole.py:150: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  logger.warn(\n",
      "actions 1\n",
      "[1, 1]\n",
      "rewards\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]]\n",
      "states var\n",
      "tensor([[[ 0.0080, -0.0462,  0.0376, -0.0016],\n",
      "         [ 0.0071,  0.1483,  0.0376, -0.2822]]], device='cuda:0')\n",
      "Traceback (most recent call last):\n",
      "  File \"run_maa2c.py\", line 94, in <module>\n",
      "    run()\n",
      "  File \"run_maa2c.py\", line 67, in run\n",
      "    a2c.train()\n",
      "  File \"/workspace/liul-storage/pytorch-DRL/MAA2C.py\", line 192, in train\n",
      "    values = self.critics[agent_id](states_var[:,agent_id,:], actions_var[:,agent_id,:])\n",
      "  File \"/workspace/liul-storage/pytorch-DRL/common/Model.py\", line 37, in __call__\n",
      "    out = th.cat([out, action], 1)\n",
      "RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 1 but got size 2 for tensor number 1 in the list.\n"
     ]
    }
   ],
   "source": [
    "!python run_maa2c.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/liul-storage/pytorch-DRL/common/Model.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.output_act(self.fc3(out))\n",
      "Traceback (most recent call last):\n",
      "  File \"run_a2c.py\", line 91, in <module>\n",
      "    run()\n",
      "  File \"run_a2c.py\", line 63, in run\n",
      "    a2c.interact()\n",
      "  File \"/workspace/liul-storage/pytorch-DRL/A2C.py\", line 60, in interact\n",
      "    super(A2C, self)._take_n_steps()\n",
      "  File \"/workspace/liul-storage/pytorch-DRL/common/Agent.py\", line 125, in _take_n_steps\n",
      "    final_value = self.value(final_state, final_action)\n",
      "  File \"/workspace/liul-storage/pytorch-DRL/A2C.py\", line 131, in value\n",
      "    value_var = self.critic(state_var, action_var)\n",
      "  File \"/workspace/liul-storage/pytorch-DRL/common/Model.py\", line 36, in __call__\n",
      "    out = nn.functional.relu(self.fc1(state)).cpu().to(device='cuda:0')\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 103, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\", line 1947, in linear\n",
      "    return torch._C._nn.linear(input, weight, bias)\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)\n"
     ]
    }
   ],
   "source": [
    "!python run_a2c.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
